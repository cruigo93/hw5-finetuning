{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import albumentations as albu\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pt\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "import models\n",
    "import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/hdd/zhuldyzzhan/imagenette2-320/noisy_imagenette.csv\"\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 12\n",
    "EPOCHS = 10\n",
    "EXPERIMENT_NAME = \"Effnet\"\n",
    "LR = 0.005\n",
    "AUGMENTATION = \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == \"Resnet\":\n",
    "        return models.Resnet()\n",
    "    elif model_name == \"VGG\":\n",
    "        return models.VGG()\n",
    "    elif model_name == \"Effnet\":\n",
    "        return models.Effnet()\n",
    "    else:\n",
    "        return models.Densenet()\n",
    "    \n",
    "def get_transforms(augmentation_style):\n",
    "    if augmentation_style == \"spatial\":\n",
    "        return transforms.get_spatial_transforms()\n",
    "    elif augmentation_style == \"hard\":\n",
    "        return transforms.get_hard_transforms()\n",
    "    else:\n",
    "        return transforms.get_light_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/albumentations/imgaug/transforms.py:384: FutureWarning: This IAAPerspective is deprecated. Please use Perspective instead\n",
      "  warnings.warn(\"This IAAPerspective is deprecated. Please use Perspective instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1175: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TRANSFORMS = get_transforms(AUGMENTATION)\n",
    "train_transforms_dict = albu.to_dict(TRAIN_TRANSFORMS)\n",
    "\n",
    "# wandb.login(key=\"SECRET_KEY_HERE\", relogin=True)\n",
    "# wandb.init(project=f\"{EXPERIMENT_NAME}-{AUGMENTATION}\", config=train_transforms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageneteModel(pt.LightningModule):\n",
    "    def __init__(self, model, criterion, optimizer, scheduler, dataloaders):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.dataloaders =  dataloaders\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10, top_k=5)\n",
    "        self.f1score = torchmetrics.F1Score(task=\"multiclass\", num_classes=10, top_k=5)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.dataloaders[\"train\"]\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.dataloaders[\"val\"]\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.dataloaders[\"test\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        pred = torch.softmax(self(x), dim=1)\n",
    "        # print(pred.shape, y)\n",
    "        loss = self.criterion(pred, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        pred = torch.softmax(self(x), dim=1)\n",
    "        loss = self.criterion(pred, y)\n",
    "        accuracy = self.accuracy(pred, y)\n",
    "        f1score = self.f1score(pred, y)\n",
    "        history = {\"val_loss\": loss, \"accuracy\": accuracy, \"f1score\": f1score}\n",
    "        self.log_dict(history, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return history\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_acc = torch.stack([x[\"accuracy\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_accuracy\", avg_acc)\n",
    "        \n",
    "        # wandb.log({\"avg_val_accuracy\": avg_acc})\n",
    "        \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        pred = torch.softmax(self(x), dim=1)\n",
    "        loss = self.criterion(pred, y)\n",
    "        accuracy = self.accuracy(pred, y)\n",
    "        f1score = self.f1score(pred, y)\n",
    "        history = {\"test_loss\": loss, \"test_accuracy\": accuracy, \"test_f1score\": f1score}\n",
    "        self.log_dict(history, on_epoch=False, on_step=True, prog_bar=True)\n",
    "        return history\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_acc = torch.stack([x[\"test_accuracy\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_test_accuracy\", avg_acc)\n",
    "        \n",
    "        # wandb.log({\"avg_test_accuracy\": avg_acc, \"num_params\": num_parameters})\n",
    "        \n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"loss\", avg_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer], [self.scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.read_csv(DATA_PATH)\n",
    "items = items_df.loc[items_df[\"is_valid\"] == False].to_dict(\"records\")\n",
    "train_items, val_items = train_test_split(items, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImagenetDataset(train_items, TRAIN_TRANSFORMS)\n",
    "val_dataset = datasets.ImagenetDataset(val_items, transforms.get_valid_transforms())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_items = items_df.loc[items_df[\"is_valid\"] == True].to_dict(\"records\")\n",
    "test_dataset = datasets.ImagenetDataset(test_items, transforms.get_valid_transforms())\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "dataLoaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader,\n",
    "    \"test\": test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataLoaders):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    logger = TensorBoardLogger(\"logs/\"+EXPERIMENT_NAME, name=EXPERIMENT_NAME)\n",
    "\n",
    "    learner = ImageneteModel(model, criterion, optimizer, scheduler, dataLoaders)\n",
    "    # Initialize a trainer\n",
    "    trainer = pt.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        max_epochs=EPOCHS,\n",
    "        precision=16,\n",
    "        logger=logger,\n",
    "        num_sanity_val_steps=0\n",
    "    )\n",
    "\n",
    "    # Train the model ⚡\n",
    "    trainer.fit(learner)\n",
    "    trainer.test(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:207: UserWarning: The parameter 'pretrained' is deprecated, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:220: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = get_model(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Effnet             | 4.0 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | accuracy  | MulticlassAccuracy | 0     \n",
      "3 | f1score   | MulticlassF1Score  | 0     \n",
      "-------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "8.041     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 75/75 [00:29<00:00,  2.53it/s, loss=1.99, v_num=1, val_loss=2.090, accuracy=0.700, f1score=0.233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:27<00:00,  2.68it/s, loss=1.91, v_num=1, val_loss=1.870, accuracy=0.853, f1score=0.284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:28<00:00,  2.66it/s, loss=1.91, v_num=1, val_loss=1.870, accuracy=0.853, f1score=0.284]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 31/31 [00:03<00:00,  8.79it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    avg_test_accuracy       0.8560869097709656\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "train(model, dataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def load_pytorch_model(state_dict, *args, **kwargs):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k\n",
    "        if name.startswith('model.'):\n",
    "            name = name.replace('model.', '') # remove `model.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/workspace/notebooks/logs/Effnet/Effnet/version_0/checkpoints/epoch=9-step=520.ckpt\"\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "imagenete_model = load_pytorch_model(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.Cifar10SearchDataset(transform=TRAIN_TRANSFORMS)\n",
    "val_dataset = datasets.Cifar10SearchDataset(train=False, transform=transforms.get_valid_transforms())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_items = items_df.loc[items_df[\"is_valid\"] == True].to_dict(\"records\")\n",
    "test_dataset = datasets.ImagenetDataset(test_items, transforms.get_valid_transforms())\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "dataLoaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader,\n",
    "    \"test\": test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenete_last_layer = copy.deepcopy(imagenete_model.base.classifier[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Effnet             | 4.0 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | accuracy  | MulticlassAccuracy | 0     \n",
      "3 | f1score   | MulticlassF1Score  | 0     \n",
      "-------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "8.041     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 10/470 [00:09<06:55,  1.11it/s, loss=2.33, v_num=2]"
     ]
    }
   ],
   "source": [
    "train(imagenete_model, dataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
